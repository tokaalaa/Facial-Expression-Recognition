{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tokaalaa/Facial-Expression-Recognition/blob/main/Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMJDRJuexzyN"
      },
      "source": [
        "# Import the dependencies\n",
        "import tensorflow as tf\n",
        " \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import gc\n",
        "gc.enable()\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "import tensorflow_hub as hub\n",
        "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT7NZrdWyAU9",
        "outputId": "3e9e785e-eec6-44a7-81a0-033b22d27b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsv94lXb_D7J"
      },
      "source": [
        "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n",
        "model = hub.load(SAVED_MODEL_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGd8eNTGyGn7"
      },
      "source": [
        "# class to load the dataset\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x /= 128.\n",
        "    x -= 1.\n",
        "    return x\n",
        "\n",
        "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
        "    # dataset: Data path\n",
        "def get_data(dataset):\n",
        "    file_stream = file_io.FileIO(dataset, mode='r')\n",
        "    data = pd.read_csv(file_stream)\n",
        "    pixels = data['pixels'].tolist()\n",
        "    images = np.empty((len(data), 75, 75, 3))\n",
        "    i = 0\n",
        "\n",
        "    for pixel_sequence in pixels:\n",
        "        single_image = [float(pixel) for pixel in pixel_sequence.split(' ')]  # Extraction of each single\n",
        "        single_image = np.asarray(single_image).reshape(48, 48) # Dimension: 48x48\n",
        "        #single_image = resize(single_image, (12, 12), order = 3, mode = 'constant') # Dimension: 139x139x3 (Bicubic)\n",
        "        ret = np.empty((48, 48, 3))  \n",
        "        ret[:, :, 0] = single_image\n",
        "        ret[:, :, 1] = single_image\n",
        "        ret[:, :, 2] = single_image\n",
        "\n",
        "        if ret.shape[-1] == 4:\n",
        "           ret = ret[...,:-1]\n",
        "        hr_size = tf.convert_to_tensor(ret.shape[:-1])\n",
        "        hr_image = tf.image.crop_to_bounding_box(ret, 0, 0, hr_size[0], hr_size[1])\n",
        "        hr_image = tf.cast(hr_image, tf.float32)\n",
        "        ret = tf.expand_dims(hr_image, 0)\n",
        "        #image = np.asarray(tf.squeeze(ret))\n",
        "        #image = tf.clip_by_value(image, 0, 255)\n",
        "        #image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
        "        #plt.imshow(image)\n",
        "        #plt.title(\"before \" + str(i))\n",
        "\n",
        "        fake_image = model(ret)\n",
        "        #print(\"finish model \" + str(i))\n",
        "        fake_image = tf.squeeze(fake_image)\n",
        "        fake_image = np.asarray(fake_image)\n",
        "        fake_image = tf.image.resize(fake_image, [75,75])\n",
        "        fake_image = tf.clip_by_value(fake_image, 0, 255)\n",
        "        fake_image = Image.fromarray(tf.cast(fake_image, tf.uint8).numpy())\n",
        "        #plt.imshow(fake_image)\n",
        "        #plt.title(\"after \" + str(i))\n",
        "        images[i, :, :, :] = fake_image\n",
        "        i += 1\n",
        "        #if i == 2:\n",
        "         #  break\n",
        "    \n",
        "    images = preprocess_input(images)\n",
        "    labels = to_categorical(data['emotion'])\n",
        "\n",
        "    return images, labels \n",
        "\n",
        "class DataLoader():\n",
        "  #root_dir : the path of the root dirctory of the dataset.\n",
        "  #task : the task of the classifier (acl, meniscus or abnormal).\n",
        "  #plane : the type of the image (sagittal, coronal or axial).\n",
        "  # train_ratio : the ratio to split the dataset to train and validation.\n",
        "     \n",
        "  def __init__(self, train_ratio = 0.9, oversampling= False, shuffle = True):\n",
        "    self.train_ratio = train_ratio\n",
        "    filname = \"/content/drive/My Drive/Facial/fer2013.csv\"\n",
        "\n",
        "    train_data_x, train_data_y  = get_data(filname)\n",
        "    train_data_x, X_test, train_data_y, y_test = train_test_split(train_data_x, train_data_y, test_size=0.1, random_state=0)\n",
        "    train_data_x, X_val, train_data_y, y_val = train_test_split(train_data_x, train_data_y, test_size=0.1, random_state=0)    \n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True)\n",
        "\n",
        "    # Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "    self.train_generator = train_datagen.flow(\n",
        "    train_data_x,\n",
        "    train_data_y,\n",
        "    batch_size  = 128)\n",
        "\n",
        "    train_datagen2 = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True)\n",
        "\n",
        "    # Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "    self.test_generator = train_datagen2.flow(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    batch_size  = 128)\n",
        "\n",
        "\n",
        "    train_datagen3 = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True)\n",
        "\n",
        "    # Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "    self.valid_generator = train_datagen3.flow(\n",
        "    X_val,\n",
        "    y_val,\n",
        "    batch_size  = 128)\n",
        "\n",
        "\n",
        "  #return : train generator\n",
        "  def get_train_generator(self):\n",
        "    return self.train_generator\n",
        " \n",
        "  #return : validation generator\n",
        "  def get_valid_generator(self):\n",
        "    return self.valid_generator\n",
        " \n",
        "  #return : test generator\n",
        "  def get_test_generator(self):\n",
        "    return self.test_generator\n",
        " \n",
        "  def __del__(self):\n",
        "    del self.train_generator\n",
        "    del self.valid_generator\n",
        "    del self.test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1o9DRLOmYU4"
      },
      "source": [
        "#dataLoader = DataLoader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB2IZITulGGc"
      },
      "source": [
        "#dataLoader = DataLoader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv65-osWdAr2"
      },
      "source": [
        "# dataLoader = DataLoader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUM-j_59mns3"
      },
      "source": [
        "# train_generator = dataLoader.get_train_generator()\n",
        "# image, label = train_generator.__getitem__(0)\n",
        "# plt.imshow(image[25])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J80XUrDQtHJd"
      },
      "source": [
        "#test_generator = dataLoader.get_test_generator()\n",
        "#image2, label2 = test_generator.__getitem__(0)\n",
        "#plt.imshow(image2[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXOpZBBU7FFa"
      },
      "source": [
        "#valid_generator = dataLoader.get_valid_generator()\n",
        "#image3, label3 = valid_generator.__getitem__(0)\n",
        "#plt.imshow(image3[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8eImUBs7qwg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}